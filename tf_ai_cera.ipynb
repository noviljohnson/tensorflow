{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\novil\\anaconda3\\envs\\tfEnv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1,0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3, -1, 1.0, 3.0, 5.0, 7.0], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:From c:\\Users\\novil\\anaconda3\\envs\\tfEnv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 14.5491\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 824us/step - loss: 14.5283\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.5075\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 537us/step - loss: 14.4867\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 14.4660\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.4453\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.4246\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 946us/step - loss: 14.4039\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 14.3832\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 14.3626\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 14.3420\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.3214\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 14.3008\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 14.2803\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 14.2597\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 14.2392\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 14.2187\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.1983\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 354us/step - loss: 14.1778\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.1574\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 248us/step - loss: 14.1370\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.1167\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 260us/step - loss: 14.0963\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.0760\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.0557\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 14.0354\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.0152\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.9950\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.9748\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.9546\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.9345\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.9143\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.8943\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.8742\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 13.8541\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.8341\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.8141\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.7942\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.7742\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.7543\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.7344\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.7146\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.6947\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.6749\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 300us/step - loss: 13.6551\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.6354\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.6156\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.5959\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.5763\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.5566\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.5370\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.5174\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.4978\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.4783\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.4587\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 13.4392\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 971us/step - loss: 13.4198\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.4003\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.3809\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.3615\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.3422\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.3228\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.3035\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.2842\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.2650\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.2457\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2265\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 267us/step - loss: 13.2074\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.1882\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.1691\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.1500\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.1309\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.1119\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.0928\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.0738\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 13.0549\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.0359\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.0170\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.9981\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.9792\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.9604\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.9416\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.9228\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.9040\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.8853\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.8666\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.8479\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8292\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 835us/step - loss: 12.8106\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.7920\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 750us/step - loss: 12.7734\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.7549\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.7363\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.7178\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.6993\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.6809\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.6625\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.6441\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.6257\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 494us/step - loss: 12.6073\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.5890\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.5707\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.5524\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.5342\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.5160\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.4978\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.4796\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.4614\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.4433\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.4252\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 801us/step - loss: 12.4071\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.3891\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.3711\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.3531\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.3351\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.3172\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.2992\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.2813\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.2635\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.2456\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2278\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.2100\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.1922\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.1745\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.1568\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.1391\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1214\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1037\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.0861\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.0685\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.0509\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 12.0334\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0159\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.9984\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.9809\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.9635\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.9460\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9286\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.9113\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.8939\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.8766\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.8593\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.8420\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.8247\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.8075\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.7903\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.7731\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.7560\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.7388\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.7217\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.7047\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.6876\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.6706\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.6536\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.6366\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.6196\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.6027\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 226us/step - loss: 11.5858\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.5689\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.5520\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.5352\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.5183\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.5016\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.4848\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.4680\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4513\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 981us/step - loss: 11.4346\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.4180\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.4013\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.3847\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.3681\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3515\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3349\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.3184\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3019\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.2854\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.2690\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 11.2525\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.2361\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.2197\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2034\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 705us/step - loss: 11.1870\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1707\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.1544\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.1381\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.1219\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1057\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.0895\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0733\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.0571\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0410\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0249\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0088\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9928\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9767\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.9607\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.9447\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.9288\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.9128\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.8969\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8810\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.8651\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8493\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8334\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8176\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8019\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7861\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.7704\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7546\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.7390\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.7233\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.7076\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.6920\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 248us/step - loss: 10.6764\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.6608\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.6453\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.6298\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.6143\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5988\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5833\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5679\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 176us/step - loss: 10.5525\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5371\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5217\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5063\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4910\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 263us/step - loss: 10.4757\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.4604\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 849us/step - loss: 10.4452\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.4299\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4147\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3995\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3843\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3692\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.3541\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3390\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3239\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 618us/step - loss: 10.3088\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.2938\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2788\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.2638\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.2488\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 245us/step - loss: 10.2339\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.2190\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.2040\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1892\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1743\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1595\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1447\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1299\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1151\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.1003\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.0856\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0709\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.0562\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0416\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 258us/step - loss: 10.0269\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0123\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9977\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.9831\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.9686\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9541\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9395\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.9251\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9106\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8961\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.8817\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.8673\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.8529\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8386\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.8242\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8099\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.7956\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7814\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.7671\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7529\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 124us/step - loss: 9.7387\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.7245\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7103\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.6962\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.6821\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6680\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6539\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6398\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6258\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6118\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5978\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 378us/step - loss: 9.5838\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.5698\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5559\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.5420\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.5281\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.5142\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5004\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.4866\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4727\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.4590\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.4452\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4315\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.4177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18ea350ef10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, ys, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.7598085]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([10.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Mnist dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist dataset is avilable within tensorflow - api call\n",
    "mnist_data = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=320)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : 0\n",
      "image : [[  0   0   0   0   0   1   0   0   0   0  41 188 103  54  48  43  87 168 133  16   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0  49 136 219 216 228 236 255 255 255 255 217 215 254 231 160  45   0   0   0   0   0]\n",
      " [  0   0   0   0   0  14 176 222 224 212 203 198 196 200 215 204 202 201 201 201 209 218 224 164   0   0   0   0]\n",
      " [  0   0   0   0   0 188 219 200 198 202 198 199 199 201 196 198 198 200 200 200 200 201 200 225  41   0   0   0]\n",
      " [  0   0   0   0  51 219 199 203 203 212 238 248 250 245 249 246 247 252 248 235 207 203 203 222 140   0   0   0]\n",
      " [  0   0   0   0 116 226 206 204 207 204 101  75  47  73  48  50  45  51  63 113 222 202 206 220 224   0   0   0]\n",
      " [  0   0   0   0 200 222 209 203 215 200   0  70  98   0 103  59  68  71  49   0 219 206 214 210 250  38   0   0]\n",
      " [  0   0   0   0 247 218 212 210 215 214   0 254 243 139 255 174 251 255 205   0 215 217 214 208 220  95   0   0]\n",
      " [  0   0   0  45 226 214 214 215 224 205   0  42  35  60  16  17  12  13  70   0 189 216 212 206 212 156   0   0]\n",
      " [  0   0   0 164 235 214 211 220 216 201  52  71  89  94  83  78  70  76  92  87 206 207 222 213 219 208   0   0]\n",
      " [  0   0   0 106 187 223 237 248 211 198 252 250 248 245 248 252 253 250 252 239 201 212 225 215 193 113   0   0]\n",
      " [  0   0   0   0   0  17  54 159 222 193 208 192 197 200 200 200 200 201 203 195 210 165   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  47 225 192 214 203 206 204 204 205 206 204 212 197 218 107   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   6   0  46 212 195 212 202 206 205 204 205 206 204 212 200 218  91   0   3   1   0   0   0]\n",
      " [  0   0   0   0   0   1   0  11 197 199 205 202 205 206 204 205 207 204 205 205 218  77   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0   2 191 198 201 205 206 205 205 206 209 206 199 209 219  74   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 188 197 200 207 207 204 207 207 210 208 198 207 221  72   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 215 198 203 206 208 205 207 207 210 208 200 202 222  75   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 212 198 209 206 209 206 208 207 211 206 205 198 221  80   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 204 201 205 208 207 205 211 205 210 210 209 195 221  96   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 202 201 205 209 207 205 213 206 210 209 210 194 217 105   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 204 204 205 208 207 205 215 207 210 208 211 193 213 115   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 204 207 207 208 206 206 215 210 210 207 212 195 210 118   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 198 208 208 208 204 207 212 212 210 207 211 196 207 121   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 198 210 207 208 206 209 213 212 211 207 210 197 207 124   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 172 210 203 201 199 204 207 205 204 201 205 197 206 127   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 188 221 214 234 236 238 244 244 244 240 243 214 224 162   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 139 146 130 135 135 137 125 124 125 121 119 114 130  76   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(f'label : {train_labels[1]}')\n",
    "print(f'image : {train_images[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18eab913ad0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[2300], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the pixel valies of the train and test images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design the model\n",
    "# input layer with shape of the data \n",
    "# output layer with sape of classes\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input to softmax function : [[1. 3. 4. 2.]]\n",
      "output of softmax funtion : [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
      "sum of outputs: 1.0\n",
      "class wtih highest probability : 2\n"
     ]
    }
   ],
   "source": [
    "# declare sample inputs and convert to a tensor\n",
    "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print(f'input to softmax function : {inputs.numpy()}')\n",
    "\n",
    "# feed the inputs to a softmax activation function\n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'output of softmax funtion : {outputs.numpy()}')\n",
    "\n",
    "# get the sum of all values after the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "# get the index with highest values\n",
    "prediction = np.argmax(outputs)\n",
    "print(f'class wtih highest probability : {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.SGD(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From c:\\Users\\novil\\anaconda3\\envs\\tfEnv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7522 - accuracy: 0.7581\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5152 - accuracy: 0.8252\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4697 - accuracy: 0.8392\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4438 - accuracy: 0.8474\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4257 - accuracy: 0.8529\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4111 - accuracy: 0.8573\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4005 - accuracy: 0.8622\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3907 - accuracy: 0.8648\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3820 - accuracy: 0.8678\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3735 - accuracy: 0.8696\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3671 - accuracy: 0.8727\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3602 - accuracy: 0.8737\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3540 - accuracy: 0.8768\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3495 - accuracy: 0.8777\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3433 - accuracy: 0.8799\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3392 - accuracy: 0.8811\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3341 - accuracy: 0.8824\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 2s 990us/step - loss: 0.3291 - accuracy: 0.8846\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3246 - accuracy: 0.8852\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3206 - accuracy: 0.8866\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3168 - accuracy: 0.8881\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3138 - accuracy: 0.8881\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3102 - accuracy: 0.8902\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3056 - accuracy: 0.8909\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3019 - accuracy: 0.8929\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2996 - accuracy: 0.8937\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2962 - accuracy: 0.8944\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2932 - accuracy: 0.8962\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2907 - accuracy: 0.8965\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2878 - accuracy: 0.8978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18ea3661610>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3528 - accuracy: 0.8731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3528008460998535, 0.8730999827384949]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with out normalizing to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a callback class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\novil\\anaconda3\\envs\\tfEnv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \"\"\"\n",
    "        halts the training when the loss falls below 0.4\n",
    "\n",
    "        Args: \n",
    "            epoch (int) - index of epoch (required but unused in the function definition below)\n",
    "      logs (dict) - metric results from the training epoch\n",
    "        \"\"\"\n",
    "\n",
    "        #check the loss\n",
    "        if (logs.get('loss') < 0.4):\n",
    "            # stop if threshold is met\n",
    "            print('\\nloss is lower than 0.4 so cancelling training ! ')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "# instantiate class\n",
    "callbacks = myCallback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model \n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=tf.optimizers.Adam(), \n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist dataset is avilable within tensorflow - api call\n",
    "mnist_data = tf.keras.datasets.fashion_mnist\n",
    "# load the dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\novil\\anaconda3\\envs\\tfEnv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\novil\\anaconda3\\envs\\tfEnv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 4.5995 - accuracy: 0.7706\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5359 - accuracy: 0.8230\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4991 - accuracy: 0.8314\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5016 - accuracy: 0.8324\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4708 - accuracy: 0.8395\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4751 - accuracy: 0.8394\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4571 - accuracy: 0.8440\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4545 - accuracy: 0.8479\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4415 - accuracy: 0.8510\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4393 - accuracy: 0.8524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b6618dc210>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
