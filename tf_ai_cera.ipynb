{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\novil\\anaconda3\\envs\\tfEnv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\novil\\anaconda3\\envs\\tfEnv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1,0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3, -1, 1.0, 3.0, 5.0, 7.0], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0135\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0132\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0129\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0126\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0124\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0121\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0119\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0116\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0114\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0112\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0109\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0107\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0105\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0103\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0101\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0097\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0093\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0091\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0089\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0087\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0085\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0083\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0082\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0080\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0078\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0077\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0075\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0074\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0072\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0071\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0069\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0066\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0065\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0064\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0062\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0061\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0060\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0057\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 850us/step - loss: 0.0054\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0052\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0051\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0050\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0049\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0048\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0047\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0046\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 679us/step - loss: 0.0045\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0044\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0043\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0042\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0041\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0039\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0038\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0037\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 231us/step - loss: 0.0036\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0036\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0035\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0034\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0033\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0032\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0031\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0029\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0025\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0024\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0024\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0023\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0023\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0022\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0021\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0021\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0019\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0019\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0018\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0018\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0018\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 507us/step - loss: 0.0017\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0016\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0015\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0011\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0011\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0010\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0010\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.8455e-04\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.6433e-04\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.4452e-04\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.2512e-04\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.0612e-04\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.8750e-04\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.6928e-04\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.5142e-04\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3393e-04\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1680e-04\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0002e-04\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.8359e-04\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.6749e-04\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5173e-04\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3628e-04\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2116e-04\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0635e-04\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9184e-04\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.7763e-04\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6371e-04\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5008e-04\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3673e-04\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.2364e-04\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1084e-04\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9829e-04\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.8600e-04\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.7396e-04\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.6217e-04\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5063e-04\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3932e-04\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2824e-04\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.1739e-04\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.0676e-04\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.9635e-04\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.8615e-04\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7617e-04\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.6639e-04\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.5681e-04\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4742e-04\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.3823e-04\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.2923e-04\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2041e-04\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1178e-04\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0332e-04\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9504e-04\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8692e-04\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7897e-04\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7119e-04\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6357e-04\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.5610e-04\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4878e-04\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4162e-04\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3460e-04\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2773e-04\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.2100e-04\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.1440e-04\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.0794e-04\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0162e-04\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9542e-04\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8935e-04\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.8341e-04\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7759e-04\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7189e-04\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.6630e-04\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6083e-04\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.5547e-04\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5023e-04\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4509e-04\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4005e-04\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3512e-04\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3029e-04\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2556e-04\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2093e-04\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1639e-04\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1195e-04\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0759e-04\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0333e-04\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9915e-04\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9506e-04\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9105e-04\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8713e-04\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.8329e-04\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7952e-04\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.7583e-04\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7222e-04\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6869e-04\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6522e-04\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6183e-04\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5850e-04\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5525e-04\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5206e-04\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 806us/step - loss: 1.4893e-04\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4587e-04\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4288e-04\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3994e-04\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3707e-04\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3425e-04\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3150e-04\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2880e-04\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2615e-04\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2356e-04\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2102e-04\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1853e-04\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1610e-04\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1372e-04\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1138e-04\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0909e-04\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0685e-04\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0466e-04\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0251e-04\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0040e-04\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.8338e-05\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.6319e-05\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.4341e-05\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.2403e-05\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 983us/step - loss: 9.0505e-05\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.8645e-05\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.6825e-05\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.5042e-05\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.3295e-05\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1584e-05\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.9908e-05\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.8267e-05\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.6659e-05\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.5083e-05\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.3541e-05\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2031e-05\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0552e-05\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9103e-05\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7683e-05\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6293e-05\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.4931e-05\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3598e-05\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.2291e-05\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.1011e-05\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9758e-05\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8530e-05\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7328e-05\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.6151e-05\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4997e-05\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3868e-05\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2761e-05\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1678e-05\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.0617e-05\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.9577e-05\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.8559e-05\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.7561e-05\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 607us/step - loss: 4.6584e-05\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5627e-05\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4691e-05\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3772e-05\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.2873e-05\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.1992e-05\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1130e-05\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0285e-05\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9458e-05\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8648e-05\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7854e-05\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7076e-05\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6314e-05\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5568e-05\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.4838e-05\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4122e-05\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.3422e-05\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.2735e-05\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.2063e-05\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1404e-05\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0759e-05\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0128e-05\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9509e-05\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.8903e-05\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8309e-05\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.7728e-05\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 473us/step - loss: 2.7159e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20209948fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, ys, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18.984797]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([10.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Mnist dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\novil\\anaconda3\\envs\\tfEnv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist dataset is avilable within tensorflow - api call\n",
    "mnist_data = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 5s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=320)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : 0\n",
      "image : [[  0   0   0   0   0   1   0   0   0   0  41 188 103  54  48  43  87 168 133  16   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0  49 136 219 216 228 236 255 255 255 255 217 215 254 231 160  45   0   0   0   0   0]\n",
      " [  0   0   0   0   0  14 176 222 224 212 203 198 196 200 215 204 202 201 201 201 209 218 224 164   0   0   0   0]\n",
      " [  0   0   0   0   0 188 219 200 198 202 198 199 199 201 196 198 198 200 200 200 200 201 200 225  41   0   0   0]\n",
      " [  0   0   0   0  51 219 199 203 203 212 238 248 250 245 249 246 247 252 248 235 207 203 203 222 140   0   0   0]\n",
      " [  0   0   0   0 116 226 206 204 207 204 101  75  47  73  48  50  45  51  63 113 222 202 206 220 224   0   0   0]\n",
      " [  0   0   0   0 200 222 209 203 215 200   0  70  98   0 103  59  68  71  49   0 219 206 214 210 250  38   0   0]\n",
      " [  0   0   0   0 247 218 212 210 215 214   0 254 243 139 255 174 251 255 205   0 215 217 214 208 220  95   0   0]\n",
      " [  0   0   0  45 226 214 214 215 224 205   0  42  35  60  16  17  12  13  70   0 189 216 212 206 212 156   0   0]\n",
      " [  0   0   0 164 235 214 211 220 216 201  52  71  89  94  83  78  70  76  92  87 206 207 222 213 219 208   0   0]\n",
      " [  0   0   0 106 187 223 237 248 211 198 252 250 248 245 248 252 253 250 252 239 201 212 225 215 193 113   0   0]\n",
      " [  0   0   0   0   0  17  54 159 222 193 208 192 197 200 200 200 200 201 203 195 210 165   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  47 225 192 214 203 206 204 204 205 206 204 212 197 218 107   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   6   0  46 212 195 212 202 206 205 204 205 206 204 212 200 218  91   0   3   1   0   0   0]\n",
      " [  0   0   0   0   0   1   0  11 197 199 205 202 205 206 204 205 207 204 205 205 218  77   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0   2 191 198 201 205 206 205 205 206 209 206 199 209 219  74   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 188 197 200 207 207 204 207 207 210 208 198 207 221  72   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 215 198 203 206 208 205 207 207 210 208 200 202 222  75   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 212 198 209 206 209 206 208 207 211 206 205 198 221  80   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 204 201 205 208 207 205 211 205 210 210 209 195 221  96   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 202 201 205 209 207 205 213 206 210 209 210 194 217 105   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 204 204 205 208 207 205 215 207 210 208 211 193 213 115   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 204 207 207 208 206 206 215 210 210 207 212 195 210 118   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 198 208 208 208 204 207 212 212 210 207 211 196 207 121   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 198 210 207 208 206 209 213 212 211 207 210 197 207 124   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 172 210 203 201 199 204 207 205 204 201 205 197 206 127   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 188 221 214 234 236 238 244 244 244 240 243 214 224 162   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 139 146 130 135 135 137 125 124 125 121 119 114 130  76   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(f'label : {train_labels[1]}')\n",
    "print(f'image : {train_images[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16114827e90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[2300], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the pixel valies of the train and test images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\novil\\anaconda3\\envs\\tfEnv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# design the model\n",
    "# input layer with shape of the data \n",
    "# output layer with sape of classes\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input to softmax function : [[1. 3. 4. 2.]]\n",
      "output of softmax funtion : [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
      "sum of outputs: 1.0\n",
      "class wtih highest probability : 2\n"
     ]
    }
   ],
   "source": [
    "# declare sample inputs and convert to a tensor\n",
    "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print(f'input to softmax function : {inputs.numpy()}')\n",
    "\n",
    "# feed the inputs to a softmax activation function\n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'output of softmax funtion : {outputs.numpy()}')\n",
    "\n",
    "# get the sum of all values after the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "# get the index with highest values\n",
    "prediction = np.argmax(outputs)\n",
    "print(f'class wtih highest probability : {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2801 - accuracy: 0.8974\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2695 - accuracy: 0.8999\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2608 - accuracy: 0.9036\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2482 - accuracy: 0.9082\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2387 - accuracy: 0.9111\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2318 - accuracy: 0.9126\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2235 - accuracy: 0.9170\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2190 - accuracy: 0.9175\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2116 - accuracy: 0.9207\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2052 - accuracy: 0.9231\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1988 - accuracy: 0.9258\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1934 - accuracy: 0.9274\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1861 - accuracy: 0.9315\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1833 - accuracy: 0.9310\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1765 - accuracy: 0.9345\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1722 - accuracy: 0.9355\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1696 - accuracy: 0.9360\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1641 - accuracy: 0.9378\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1591 - accuracy: 0.9405\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1582 - accuracy: 0.9406\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1527 - accuracy: 0.9432\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1491 - accuracy: 0.9441\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1455 - accuracy: 0.9450\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1425 - accuracy: 0.9462\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1392 - accuracy: 0.9469\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1372 - accuracy: 0.9480\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1324 - accuracy: 0.9500\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1307 - accuracy: 0.9511\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1283 - accuracy: 0.9509\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1279 - accuracy: 0.9521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16115585ad0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43687427043914795, 0.8896999955177307]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
